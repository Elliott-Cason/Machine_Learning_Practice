{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Tensor Flow: Linear Regression Using Estimators**"
      ],
      "metadata": {
        "id": "o_sLl21p2cYY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVJB3_1EKA8N"
      },
      "outputs": [],
      "source": [
        "!pip install -q sklearn\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BGV = pd.read_csv(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/BGVData/BookersLastFiveYears.csv')\n",
        "\n",
        "BGV['TourDate1'] = pd.to_datetime(BGV['TourDate1'])\n",
        "\n",
        "BGV['TourWave2'] = BGV['TourWave2'].fillna(0).astype(int)\n",
        "#contains zeroes, should I drop?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "0P556AkgI1oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only look at showed tours and only 4 main columns\n",
        "BGV = BGV.loc[BGV['TourStatus2'] == 'Showed']\n",
        "\n",
        "BGV = BGV[['TourMonth', 'ProgramName', 'TourWave', 'ContractStatus1']]\n",
        "\n",
        "BGV['TourWave'] = BGV['TourWave'].fillna(0).astype(int)\n",
        "#BGV['TourMonth'] = BGV['TourMonth'].astype(float)\n",
        "BGV.dropna(how=\"any\",inplace = True)"
      ],
      "metadata": {
        "id": "rdwgSvlVKQGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to replace 'ContractStatus1' column with 1 if 'Active\\r\\nActive' and 0 otherwise\n",
        "BGV['ContractStatus1'] = BGV['ContractStatus1'].replace({'Active\\r\\nActive': 1})\n",
        "BGV['ContractStatus1'] = BGV['ContractStatus1'].replace(['\\r\\n', 'Canceled\\r\\nUpgrade', 'Canceled\\r\\nExpired', 'Canceled\\r\\nRescind', 'Canceled\\r\\nForfeit', 'Canceled\\r\\nNot Executed',\n",
        "                                                         'Canceled\\r\\nRewrite', 'Active\\r\\nPipeline', 'Active\\r\\nFuture CXL', 'Sold\\r\\nSold ', 'Suspense\\r\\nSuspense',\n",
        "                                                         'Pender\\r\\nPender', 'Active\\r\\nNeeds Paperwork', 'Canceled\\r\\nRewrite-Error', 'Canceled\\r\\nRewrite-Adjustment',\n",
        "                                                         'Active\\r\\nPartial Future CXL', 'Mail Out\\r\\nMailout', 'Canceled\\r\\nTransferred', 'Mail Out\\r\\nPender'], 0)"
      ],
      "metadata": {
        "id": "1Lr2VOYZJUrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make not numbers into numbers\n",
        "\n",
        "CATEGORICAL_COLUMNS = ['ProgramName', 'TourMonth', 'TourWave']\n",
        "\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = BGV[feature_name].unique()  # gets a list of all unique values from given feature column\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(key=feature_name, vocabulary_list=vocabulary))\n",
        "\n",
        "print(feature_columns)"
      ],
      "metadata": {
        "id": "EDfweCROgfR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dftrain = BGV[:57250] # training 80% data\n",
        "dfeval = BGV[57250:] # testing 20% data\n",
        "\n",
        "y_train = dftrain.pop('ContractStatus1')\n",
        "y_eval = dfeval.pop('ContractStatus1')"
      ],
      "metadata": {
        "id": "0WkcbNlenyMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training: Input\n",
        "\n",
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():  # inner function, this will be returned\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)  # randomize order of data\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
        "    return ds  # return a batch of the dataset\n",
        "  return input_function  # return a function object for use\n",
        "\n",
        "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
      ],
      "metadata": {
        "id": "-7biF2uRmqk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "# We create a linear estimtor by passing the feature columns we created earlier"
      ],
      "metadata": {
        "id": "4Q7FFNwTKw6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_est.train(train_input_fn)  # train\n",
        "result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on testing data\n",
        "\n",
        "clear_output()  # clears console output\n",
        "print(result['accuracy'])  # the result variable is simply a dict of stats about our model"
      ],
      "metadata": {
        "id": "GH-fL4U_Kxj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram showing the probability of purchase for each showed tour in the training set\n",
        "pred_dicts = list(linear_est.predict(eval_input_fn))\n",
        "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
        "\n",
        "probs.plot(kind='hist', bins=50, title='predicted probabilities')"
      ],
      "metadata": {
        "id": "RYxDTb3Ykiia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs.mean()"
      ],
      "metadata": {
        "id": "Kx8ChlkmGN0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tensor Flow: Classification Using Deep Neural Network**"
      ],
      "metadata": {
        "id": "6S6q49Yq2bIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BGV = pd.read_csv(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/BGVData/BookersLastFiveYears.csv')\n",
        "\n",
        "BGV['TourDate1'] = pd.to_datetime(BGV['TourDate1'])\n",
        "BGV['TourWave'] = BGV['TourWave'].fillna(0).astype(int)\n",
        "BGV = BGV.loc[BGV['TourStatus2'] == 'Showed']\n",
        "BGV = BGV[['TourMonth', 'ProgramName', 'TourWave', 'ContractStatus1']]\n",
        "BGV.dropna(how=\"any\",inplace = True)\n",
        "\n",
        "# Need to replace 'ContractStatus1' column with 1 if 'Active\\r\\nActive' and 0 otherwise\n",
        "BGV['ContractStatus1'] = BGV['ContractStatus1'].replace({'Active\\r\\nActive': 1})\n",
        "BGV['ContractStatus1'] = BGV['ContractStatus1'].replace(['\\r\\n', 'Canceled\\r\\nUpgrade', 'Canceled\\r\\nExpired', 'Canceled\\r\\nRescind', 'Canceled\\r\\nForfeit', 'Canceled\\r\\nNot Executed',\n",
        "                                                         'Canceled\\r\\nRewrite', 'Active\\r\\nPipeline', 'Active\\r\\nFuture CXL', 'Sold\\r\\nSold ', 'Suspense\\r\\nSuspense',\n",
        "                                                         'Pender\\r\\nPender', 'Active\\r\\nNeeds Paperwork', 'Canceled\\r\\nRewrite-Error', 'Canceled\\r\\nRewrite-Adjustment',\n",
        "                                                         'Active\\r\\nPartial Future CXL', 'Mail Out\\r\\nMailout', 'Canceled\\r\\nTransferred', 'Mail Out\\r\\nPender'], 0)"
      ],
      "metadata": {
        "id": "ndc2HQ2S6WQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = BGV[:57250] # training 80% data\n",
        "test = BGV[57250:] # testing 20% data\n",
        "\n",
        "train_y = train.pop('ContractStatus1')\n",
        "test_y = test.pop('ContractStatus1')"
      ],
      "metadata": {
        "id": "UUefv06m7Ze4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Function\n",
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle and repeat if you are in training mode.\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    \n",
        "    return dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "5gdT9_Wd87kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make not numbers into numbers\n",
        "\n",
        "CATEGORICAL_COLUMNS = ['ProgramName', 'TourMonth', 'TourWave']\n",
        "\n",
        "my_feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = train[feature_name].unique()  # gets a list of all unique values from given feature column\n",
        "  categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(key=feature_name, vocabulary_list=vocabulary)\n",
        "  my_feature_columns.append(tf.feature_column.indicator_column(categorical_column))\n",
        "print(my_feature_columns)"
      ],
      "metadata": {
        "id": "wI1hDQzN_ETo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    # Two hidden layers of 30 and 10 nodes respectively.\n",
        "    hidden_units=[30, 10],\n",
        "    # The model must choose between 2 states.\n",
        "    n_classes=2)"
      ],
      "metadata": {
        "id": "Q9em-gpW_wmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
        "    steps=5000)\n",
        "# We include a lambda to avoid creating an inner function previously"
      ],
      "metadata": {
        "id": "uxmYN_x4_ykA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "metadata": {
        "id": "WEP5vAGWjDR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_fn(features, batch_size=256):\n",
        "    # Convert the inputs to a Dataset without labels.\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "features = ['TourMonth', 'TourWave']\n",
        "predict = {}\n",
        "\n",
        "# Retrieve Program Name from user. Only allow acceptable strings\n",
        "print(\"Please type acceptable options as prompted.\")\n",
        "print(\"Acceptable options: \" + str(train['ProgramName'].unique()))\n",
        "valid=False\n",
        "while valid == False:\n",
        "  val = input('Program Name: ')\n",
        "  if str(val) in train['ProgramName'].unique():\n",
        "    valid=True\n",
        "  else: print('Please try again')\n",
        "\n",
        "predict['ProgramName'] = [str(val)]\n",
        "\n",
        "# Retrieve Tour Month and Tour Wave from user. Only allow acceptable ints\n",
        "for feature in features:\n",
        "  valid=False\n",
        "  print(\"Acceptable options: \"+str(np.sort(train[feature].unique())))\n",
        "  while valid == False:\n",
        "    val = input(feature+': ')\n",
        "    if int(val) in np.sort(train[feature].unique()):\n",
        "      valid=True\n",
        "    else: print('Please try again')\n",
        "  \n",
        "  predict[feature] = [int(val)]\n",
        "\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Guest has a {:.1f}% chance to purchase'.format(100 - 100 * probability))"
      ],
      "metadata": {
        "id": "zYqnMc3ejoLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Algorithm predicted an average purchase rate of {:.1f}%, whereas the actual purchase rate from training set is {:.1f}%'.format(\n",
        "      eval_result['prediction/mean']*100, test_y.mean()*100))"
      ],
      "metadata": {
        "id": "87l1T3gbdaO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tensor Flow: Classification Using Linear Classifier**"
      ],
      "metadata": {
        "id": "P7V-kCG9785f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary \n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BGV = pd.read_csv(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/BGVData/BookersLastFiveYears.csv')\n",
        "\n",
        "BGV['TourDate1'] = pd.to_datetime(BGV['TourDate1'])\n",
        "BGV['TourWave'] = BGV['TourWave'].fillna(0).astype(int)\n",
        "BGV = BGV.loc[BGV['TourStatus2'] == 'Showed']\n",
        "BGV = BGV[['TourMonth', 'ProgramName', 'TourWave', 'ContractStatus1']]\n",
        "BGV.dropna(how=\"any\",inplace = True)\n",
        "\n",
        "# Need to replace 'ContractStatus1' column with 1 if 'Active\\r\\nActive' and 0 otherwise\n",
        "BGV['ContractStatus1'] = BGV['ContractStatus1'].replace({'Active\\r\\nActive': 1})\n",
        "BGV['ContractStatus1'] = BGV['ContractStatus1'].replace(['\\r\\n', 'Canceled\\r\\nUpgrade', 'Canceled\\r\\nExpired', 'Canceled\\r\\nRescind', 'Canceled\\r\\nForfeit', 'Canceled\\r\\nNot Executed',\n",
        "                                                         'Canceled\\r\\nRewrite', 'Active\\r\\nPipeline', 'Active\\r\\nFuture CXL', 'Sold\\r\\nSold ', 'Suspense\\r\\nSuspense',\n",
        "                                                         'Pender\\r\\nPender', 'Active\\r\\nNeeds Paperwork', 'Canceled\\r\\nRewrite-Error', 'Canceled\\r\\nRewrite-Adjustment',\n",
        "                                                         'Active\\r\\nPartial Future CXL', 'Mail Out\\r\\nMailout', 'Canceled\\r\\nTransferred', 'Mail Out\\r\\nPender'], 0)"
      ],
      "metadata": {
        "id": "5jiX1Llu785f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test to see if I should implement preprocessing by making values between 0-1\n",
        "'''BGV['TourMonth'] = BGV['TourMonth'] / 12\n",
        "BGV['TourWave'] = BGV['TourWave'] / 1600\n",
        "BGV.head()'''"
      ],
      "metadata": {
        "id": "ni0aOWOJHkWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = BGV[:57250] # training 80% data\n",
        "test = BGV[57250:] # testing 20% data\n",
        "\n",
        "train_y = train.pop('ContractStatus1')\n",
        "test_y = test.pop('ContractStatus1')"
      ],
      "metadata": {
        "id": "IHQ8BO-J785g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Function\n",
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle and repeat if you are in training mode.\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    \n",
        "    return dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "Uka2M2kL785g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make not numbers into numbers\n",
        "\n",
        "CATEGORICAL_COLUMNS = ['ProgramName', 'TourMonth', 'TourWave']\n",
        "\n",
        "my_feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = train[feature_name].unique()  # gets a list of all unique values from given feature column\n",
        "  categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(key=feature_name, vocabulary_list=vocabulary)\n",
        "  my_feature_columns.append(tf.feature_column.indicator_column(categorical_column))\n",
        "\n",
        "# Preprocessing Test\n",
        "'''NUMERIC_COLUMNS = ['TourMonth', 'TourWave']\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
        "\n",
        "print(my_feature_columns)'''"
      ],
      "metadata": {
        "id": "q7UErAYq785g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
        "classifier = tf.estimator.LinearClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    # Two hidden layers of 30 and 10 nodes respectively.\n",
        "    n_classes=2)"
      ],
      "metadata": {
        "id": "AiogC5tp785g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
        "    steps=5000)\n",
        "# We include a lambda to avoid creating an inner function previously"
      ],
      "metadata": {
        "id": "LzTX9VuR785g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "metadata": {
        "id": "aKWxVPaP785h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''train['TourWave'] = train['TourWave'] * 1600\n",
        "train['TourMonth'] = train['TourMonth'] * 12'''"
      ],
      "metadata": {
        "id": "fgw5I65A4CXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_fn(features, batch_size=256):\n",
        "    # Convert the inputs to a Dataset without labels.\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "features = ['TourMonth', 'TourWave']\n",
        "predict = {}\n",
        "\n",
        "# Retrieve Program Name from user. Only allow acceptable strings\n",
        "print(\"Please type acceptable options as prompted.\")\n",
        "print(\"Acceptable options: \" + str(train['ProgramName'].unique()))\n",
        "valid=False\n",
        "while valid == False:\n",
        "  val = input('Program Name: ')\n",
        "  if str(val) in train['ProgramName'].unique():\n",
        "    valid=True\n",
        "  else: print('Please try again')\n",
        "\n",
        "predict['ProgramName'] = [str(val)]\n",
        "\n",
        "# Retrieve Tour Month and Tour Wave from user. Only allow acceptable ints\n",
        "for feature in features:\n",
        "  valid=False\n",
        "  print(\"Acceptable options: \"+str(np.sort(train[feature].astype(int).unique())))\n",
        "  while valid == False:\n",
        "    val = input(feature+': ')\n",
        "    if int(val) in np.sort(train[feature].astype(int).unique()):\n",
        "      valid=True\n",
        "    else: print('Please try again')\n",
        "  \n",
        "  predict[feature] = [int(val)]\n",
        "\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Guest has a {:.1f}% chance to purchase'.format(100 - 100 * probability))"
      ],
      "metadata": {
        "id": "o3drS4ZS785h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Algorithm predicted an average purchase rate of {:.1f}%, whereas the actual purchase rate from training set is {:.1f}%'.format(\n",
        "      eval_result['prediction/mean']*100, test_y.mean()*100))"
      ],
      "metadata": {
        "id": "ANO6sPpo785h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dict"
      ],
      "metadata": {
        "id": "JbN-JIg55Hzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tensor Flow: Classification Using Linear Classifier with Preprocessing**"
      ],
      "metadata": {
        "id": "dwynS8UC7Ww3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BGV = pd.read_csv(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/BGVData/BookersLastFiveYears.csv')\n",
        "\n",
        "# Convert to datetime and remove any rows with empty data. Only look at showed tours and relevant data.\n",
        "BGV['TourDate1'] = pd.to_datetime(BGV['TourDate1'])\n",
        "BGV['TourWave'] = BGV['TourWave'].fillna(0).astype(int)\n",
        "BGV = BGV.loc[BGV['TourStatus2'] == 'Showed']\n",
        "BGV = BGV[['TourMonth', 'ProgramName', 'TourWave', 'ContractStatus1']]\n",
        "BGV.dropna(how=\"any\",inplace = True)\n",
        "\n",
        "# Replace 'ContractStatus1' with 1 if 'Active\\r\\nActive' and 0 otherwise\n",
        "BGV['ContractStatus1'] = BGV['ContractStatus1'].replace({'Active\\r\\nActive': 1})\n",
        "BGV['ContractStatus1'] = BGV['ContractStatus1'].replace(['\\r\\n', 'Canceled\\r\\nUpgrade', 'Canceled\\r\\nExpired', 'Canceled\\r\\nRescind', 'Canceled\\r\\nForfeit', 'Canceled\\r\\nNot Executed',\n",
        "                                                         'Canceled\\r\\nRewrite', 'Active\\r\\nPipeline', 'Active\\r\\nFuture CXL', 'Sold\\r\\nSold ', 'Suspense\\r\\nSuspense',\n",
        "                                                         'Pender\\r\\nPender', 'Active\\r\\nNeeds Paperwork', 'Canceled\\r\\nRewrite-Error', 'Canceled\\r\\nRewrite-Adjustment',\n",
        "                                                         'Active\\r\\nPartial Future CXL', 'Mail Out\\r\\nMailout', 'Canceled\\r\\nTransferred', 'Mail Out\\r\\nPender'], 0)"
      ],
      "metadata": {
        "id": "b7yQ6i577WxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data by making values between 0-1\n",
        "BGV['TourMonth'] = BGV['TourMonth'] / 12\n",
        "BGV['TourWave'] = BGV['TourWave'] / 1600"
      ],
      "metadata": {
        "id": "GI2YQACM7WxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train 80% and test 20%\n",
        "train = BGV[:57250]\n",
        "test = BGV[57250:]\n",
        "\n",
        "# Pop out data on if they purchased\n",
        "train_y = train.pop('ContractStatus1')\n",
        "test_y = test.pop('ContractStatus1')"
      ],
      "metadata": {
        "id": "THPcs6RY7WxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Function\n",
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle and repeat if you are in training mode.\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    \n",
        "    return dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "ZTvn4iX17WxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into floats and not floats\n",
        "\n",
        "CATEGORICAL_COLUMNS = ['ProgramName']\n",
        "\n",
        "my_feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = train[feature_name].unique()\n",
        "  categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(key=feature_name, vocabulary_list=vocabulary)\n",
        "  my_feature_columns.append(tf.feature_column.indicator_column(categorical_column))\n",
        "\n",
        "# Preprocessing Test\n",
        "NUMERIC_COLUMNS = ['TourMonth', 'TourWave']\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
        "\n",
        "print(my_feature_columns)"
      ],
      "metadata": {
        "id": "wydvgFSA7WxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
        "classifier = tf.estimator.LinearClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    n_classes=2)"
      ],
      "metadata": {
        "id": "G526JvPa7WxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train algorithm\n",
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
        "    steps=5000)"
      ],
      "metadata": {
        "id": "GmTlgDWU7WxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print accuracy from testing set\n",
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "metadata": {
        "id": "mvPBd4Ur7WxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn back into readable data for the user\n",
        "train['TourWave'] = train['TourWave'] * 1600\n",
        "train['TourMonth'] = train['TourMonth'] * 12"
      ],
      "metadata": {
        "id": "Fd8wSEbx7WxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Algorithm predicted an average purchase rate of {:.1f}%, whereas the actual purchase rate from training set is {:.1f}%'.format(\n",
        "      eval_result['prediction/mean']*100, test_y.mean()*100))"
      ],
      "metadata": {
        "id": "4IPBgqCyp9dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Request specific instance from user and calculate estimated purchase rate\n",
        "\n",
        "def input_fn(features, batch_size=256):\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "predict = {}\n",
        "\n",
        "# Retrieve Program Name from user. Only allow acceptable strings\n",
        "print(\"Please type acceptable options as prompted.\")\n",
        "print(\"Acceptable options: \" + str(train['ProgramName'].unique()))\n",
        "valid=False\n",
        "while valid == False:\n",
        "  val = input('Program Name: ')\n",
        "  if str(val) in train['ProgramName'].unique():\n",
        "    valid=True\n",
        "  else:\n",
        "    print('Please try again...')\n",
        "  predict['ProgramName'] = [str(val)]\n",
        "\n",
        "\n",
        "# Retrieve Tour Month from user. Only allow acceptable ints\n",
        "valid=False\n",
        "print(\"Acceptable options: \"+str(np.sort(train['TourMonth'].astype(int).unique())))\n",
        "while valid == False:\n",
        "  val = input('Tour Month: ')\n",
        "  if val.isdigit():\n",
        "    val = int(val)\n",
        "    if val in np.sort(train['TourMonth'].astype(int).unique()):\n",
        "      valid=True\n",
        "    else: print('Please try again...')\n",
        "    predict['TourMonth'] = [val/12]\n",
        "  else: print('Please try again...')\n",
        "\n",
        "\n",
        "# Retrieve Tour Wave from user. Only allow acceptable ints\n",
        "valid=False\n",
        "print(\"Acceptable options: \"+str(np.sort(train['TourWave'].astype(int).unique())))\n",
        "while valid == False:\n",
        "  val = input('Tour Wave: ')\n",
        "  if val.isdigit():\n",
        "    val = int(val)\n",
        "    if val in np.sort(train['TourWave'].astype(int).unique()):\n",
        "      valid=True\n",
        "    else:\n",
        "      print('Please try again...')\n",
        "    predict['TourWave'] = [val/1600]\n",
        "  else: print('Please try again...')\n",
        "\n",
        "\n",
        "# Run the prediction.\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Guest has a {:.1f}% chance to purchase'.format(100 - 100 * probability))"
      ],
      "metadata": {
        "id": "hwrJK0cy7WxL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}